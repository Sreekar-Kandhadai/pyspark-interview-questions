{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnhkO6MtcKLziml0HMsR9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar-Kandhadai/pyspark-interview-questions/blob/main/Eclerx1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg-Y5Itfp3xt"
      },
      "outputs": [],
      "source": [
        "ğğ®ğğ¬ğ­ğ¢ğ¨ğ§\n",
        "You are given a PySpark DataFrame containing a column named input_date with dates in various formats. The task is to:\n",
        "\n",
        "- Validate the date format and filter rows where input_date matches the format \"yyyy-MM-dd\".\n",
        "- Transform valid dates into the format \"MM/dd/yyyy\".\n",
        "- For invalid dates, replace them with the string \"Invalid Date\".\n",
        "- Output the transformed DataFrame with a new column named validated_date.\n",
        "\n",
        "\n",
        "ğ¬ğœğ¡ğğ¦ğš\n",
        "data = [ (\"2023-12-31\",), (\"31-12-2023\",),\n",
        " (\"2023/12/31\",), (\"2024-01-01\",),\n",
        " (\"13-01-2023\",), (\"invalid\",), (\"2022-02-28\",) ]\n",
        "\n",
        " columns = [\"input_date\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark=SparkSession.builder.appName(\"learning\").getOrCreate()\n",
        "\n",
        "\n",
        "data=[ (\"2023-12-31\",), (\"31-12-2023\",),\n",
        " (\"2023/12/31\",), (\"2024-01-01\",),\n",
        " (\"13-01-2023\",), (\"invalid\",), (\"2022-02-28\",) ]\n",
        "\n",
        "schema=[\"input_date\"]\n",
        "\n",
        "df=spark.createDataFrame(data,schema)\n",
        "\n",
        "df.show()\n",
        "\n",
        "df1=df.withColumn(\"validated_date\",when(  to_date(col('input_date'),'yyyy-MM-dd').isNotNull(),date_format(to_date(col('input_date'),'yyyy-MM-dd'),'MM/dd/yyyy'))\\\n",
        "      .otherwise(\"Invalid_date\"))\n",
        "\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alU2VuURqW3g",
        "outputId": "5e2fc44b-5b9c-4a45-df1c-457571988c5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|input_date|\n",
            "+----------+\n",
            "|2023-12-31|\n",
            "|31-12-2023|\n",
            "|2023/12/31|\n",
            "|2024-01-01|\n",
            "|13-01-2023|\n",
            "|   invalid|\n",
            "|2022-02-28|\n",
            "+----------+\n",
            "\n",
            "+----------+--------------+\n",
            "|input_date|validated_date|\n",
            "+----------+--------------+\n",
            "|2023-12-31|    12/31/2023|\n",
            "|31-12-2023|  Invalid_date|\n",
            "|2023/12/31|  Invalid_date|\n",
            "|2024-01-01|    01/01/2024|\n",
            "|13-01-2023|  Invalid_date|\n",
            "|   invalid|  Invalid_date|\n",
            "|2022-02-28|    02/28/2022|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}