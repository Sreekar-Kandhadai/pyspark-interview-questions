{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZRQKTwI4kzTHuCSNBgcKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar-Kandhadai/pyspark-interview-questions/blob/main/Eclerx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTmBiySY5Dll"
      },
      "outputs": [],
      "source": [
        "\n",
        "𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧\n",
        "You are working as a Data Engineer and need to clean up a dataset that contains customer order information. The dataset includes details such as the customer ID, order ID,\n",
        "order date, and the total amount. Due to a data processing issue, some rows are duplicated, and you need to remove duplicates based on a composite key of customer_id and order_id,\n",
        " keeping only the latest order (based on the order_date).\n",
        "You need to remove the duplicate rows based on the composite key (customer_id, order_id) and retain only the row with the latest order_date for each combination of customer_id and\n",
        " order_id.\n",
        "\n",
        "𝐬𝐜𝐡𝐞𝐦𝐚\n",
        "data = [ (101, 1001, \"2025-01-15\", 500.00), (102, 1002, \"2025-01-14\", 300.00), (101, 1001, \"2025-01-17\", 550.00), (103, 1003, \"2025-01-16\", 450.00),\n",
        "(102, 1002, \"2025-01-18\", 320.00), (103, 1003, \"2025-01-19\", 460.00) ]\n",
        "\n",
        "# Define schema schema = [\"customer_id\", \"order_id\", \"order_date\", \"total_amount\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark=SparkSession.builder.appName(\"learning\").getOrCreate()\n",
        "\n",
        "data=[ (101, 1001, \"2025-01-15\", 500.00), (102, 1002, \"2025-01-14\", 300.00), (101, 1001, \"2025-01-17\", 550.00), (103, 1003, \"2025-01-16\", 450.00),\n",
        "(102, 1002, \"2025-01-18\", 320.00), (103, 1003, \"2025-01-19\", 460.00) ]\n",
        "\n",
        "schema=[\"customer_id\", \"order_id\", \"order_date\", \"total_amount\"]\n",
        "\n",
        "df=spark.createDataFrame(data,schema)\n",
        "\n",
        "df.show()\n",
        "\n",
        "window_spec=Window.partitionBy('customer_id','order_id').orderBy(col('order_date').desc())\n",
        "\n",
        "df1=df.withColumn('rank',dense_rank().over(window_spec)).filter(\"rank==1\").select(\"customer_id\",\"order_id\",\"order_date\",\"total_amount\")\n",
        "\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oPy-0Td5H3Y",
        "outputId": "57ef8672-3c96-499b-87b6-0b082868a905"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+----------+------------+\n",
            "|customer_id|order_id|order_date|total_amount|\n",
            "+-----------+--------+----------+------------+\n",
            "|        101|    1001|2025-01-15|       500.0|\n",
            "|        102|    1002|2025-01-14|       300.0|\n",
            "|        101|    1001|2025-01-17|       550.0|\n",
            "|        103|    1003|2025-01-16|       450.0|\n",
            "|        102|    1002|2025-01-18|       320.0|\n",
            "|        103|    1003|2025-01-19|       460.0|\n",
            "+-----------+--------+----------+------------+\n",
            "\n",
            "+-----------+--------+----------+------------+\n",
            "|customer_id|order_id|order_date|total_amount|\n",
            "+-----------+--------+----------+------------+\n",
            "|        101|    1001|2025-01-17|       550.0|\n",
            "|        102|    1002|2025-01-18|       320.0|\n",
            "|        103|    1003|2025-01-19|       460.0|\n",
            "+-----------+--------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}