{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8WFr2taAQmL98sAxZjNUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar-Kandhadai/pyspark-interview-questions/blob/main/Imp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf_RdKXQC31u"
      },
      "outputs": [],
      "source": [
        "ðð®ðžð¬ð­ð¢ð¨ð§:\n",
        "Scenario:\n",
        "You are working as a Data Engineer for a retail company. The company has provided you with customer transaction data in a Python dictionary.\n",
        "Your task is to create a PySpark DataFrame from the given dictionary and answer the following:\n",
        "Display the schema of the created DataFrame.\n",
        "Filter the DataFrame to show only transactions where the amount is greater than 100.\n",
        "Add a new column discounted_amount that applies a 10% discount to all transactions.\n",
        "\n",
        "ð¬ðœð¡ðžð¦ðš ðšð§ð ððšð­ðšð¬ðžð­\n",
        "transaction_data = [\n",
        " {\"transaction_id\": 1, \"customer_id\": 101, \"amount\": 150, \"date\": \"2025-01-01\"},\n",
        " {\"transaction_id\": 2, \"customer_id\": 102, \"amount\": 90, \"date\": \"2025-01-02\"},\n",
        " {\"transaction_id\": 3, \"customer_id\": 103, \"amount\": 200, \"date\": \"2025-01-03\"},\n",
        " {\"transaction_id\": 4, \"customer_id\": 104, \"amount\": 50, \"date\": \"2025-01-04\"},\n",
        " {\"transaction_id\": 5, \"customer_id\": 105, \"amount\": 120, \"date\": \"2025-01-05\"}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark=SparkSession.builder.appName('learning').getOrCreate()\n",
        "\n",
        "data=transaction_data = [\n",
        " {\"transaction_id\": 1, \"customer_id\": 101, \"amount\": 150, \"date\": \"2025-01-01\"},\n",
        " {\"transaction_id\": 2, \"customer_id\": 102, \"amount\": 90, \"date\": \"2025-01-02\"},\n",
        " {\"transaction_id\": 3, \"customer_id\": 103, \"amount\": 200, \"date\": \"2025-01-03\"},\n",
        " {\"transaction_id\": 4, \"customer_id\": 104, \"amount\": 50, \"date\": \"2025-01-04\"},\n",
        " {\"transaction_id\": 5, \"customer_id\": 105, \"amount\": 120, \"date\": \"2025-01-05\"}\n",
        "]\n",
        "\n",
        "df=spark.createDataFrame(data)\n",
        "\n",
        "df.printSchema()\n",
        "\n",
        "df.show()\n",
        "\n",
        "df1=df.filter(col('amount') > 100 )\n",
        "\n",
        "df1.show()\n",
        "\n",
        "df2=df.withColumn('discounted_amount',col('amount')*0.9)\n",
        "\n",
        "df2.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z7xhmLyC6MQ",
        "outputId": "96efded7-c52b-4eb5-ae01-94754809a6dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- amount: long (nullable = true)\n",
            " |-- customer_id: long (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- transaction_id: long (nullable = true)\n",
            "\n",
            "+------+-----------+----------+--------------+\n",
            "|amount|customer_id|      date|transaction_id|\n",
            "+------+-----------+----------+--------------+\n",
            "|   150|        101|2025-01-01|             1|\n",
            "|    90|        102|2025-01-02|             2|\n",
            "|   200|        103|2025-01-03|             3|\n",
            "|    50|        104|2025-01-04|             4|\n",
            "|   120|        105|2025-01-05|             5|\n",
            "+------+-----------+----------+--------------+\n",
            "\n",
            "+------+-----------+----------+--------------+\n",
            "|amount|customer_id|      date|transaction_id|\n",
            "+------+-----------+----------+--------------+\n",
            "|   150|        101|2025-01-01|             1|\n",
            "|   200|        103|2025-01-03|             3|\n",
            "|   120|        105|2025-01-05|             5|\n",
            "+------+-----------+----------+--------------+\n",
            "\n",
            "+------+-----------+----------+--------------+-----------------+\n",
            "|amount|customer_id|      date|transaction_id|discounted_amount|\n",
            "+------+-----------+----------+--------------+-----------------+\n",
            "|   150|        101|2025-01-01|             1|            135.0|\n",
            "|    90|        102|2025-01-02|             2|             81.0|\n",
            "|   200|        103|2025-01-03|             3|            180.0|\n",
            "|    50|        104|2025-01-04|             4|             45.0|\n",
            "|   120|        105|2025-01-05|             5|            108.0|\n",
            "+------+-----------+----------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}