{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3PFI2SuutbXR7U5vOyua5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar-Kandhadai/pyspark-interview-questions/blob/main/capgemini1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfhIMsCR7hea"
      },
      "outputs": [],
      "source": [
        "\n",
        "ùêêùêÆùêûùê¨ùê≠ùê¢ùê®ùêß\n",
        "You are working as a Data Engineer for a company that deals with customer data across different regions. The company uses Apache Spark to process large datasets.\n",
        "Your task is to fill the missing values in the DataFrame dynamically based on the column data types.\n",
        "\n",
        "The columns contain different types of data, including numeric, categorical, and string values. Your objective is to:\n",
        "1. Fill numeric columns with the median value.\n",
        "2. Fill categorical columns with the most frequent value.\n",
        "3. Fill string columns with \"Unknown\".\n",
        "\n",
        "ùê¨ùêúùê°ùêûùê¶ùêö\n",
        "data = [ (1, 25, 'North', 'M', '2025-01-01', 150),\n",
        " (2, None, 'East', None, '2025-01-02', None),\n",
        " (3, 30, 'South', 'F', None, 200),\n",
        " (4, 22, None, 'M', '2025-01-03', 180),\n",
        " (5, 28, 'West', 'F', None, None), ]\n",
        "\n",
        "# Column names columns = ['Customer_ID', 'Age', 'Region', 'Gender', 'Last_Visit', 'Purchase_Amount']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark=SparkSession.builder.appName(\"learning\").getOrCreate()\n",
        "\n",
        "data= [ (1, 25, 'North', 'M', '2025-01-01', 150),\n",
        " (2, None, 'East', None, '2025-01-02', None),\n",
        " (3, 30, 'South', 'F', None, 200),\n",
        " (4, 22, None, 'M', '2025-01-03', 180),\n",
        " (5, 28, 'West', 'F', None, None), ]\n",
        "\n",
        "schema=['Customer_ID', 'Age', 'Region', 'Gender', 'Last_Visit', 'Purchase_Amount']\n",
        "\n",
        "df=spark.createDataFrame(data,schema)\n",
        "\n",
        "df.printSchema()\n",
        "\n",
        "print(df.dtypes)\n",
        "\n",
        "df.show()\n",
        "\n",
        "def fill_missing_values(df):\n",
        "\n",
        "  column_types=df.dtypes\n",
        "\n",
        "  for column,d_type in column_types:\n",
        "\n",
        "    if d_type=='int' or d_type=='bigint' or d_type=='long':\n",
        "\n",
        "      median_value=df.approxQuantile(column,[0.5],0)[0]\n",
        "\n",
        "      df=df.fillna({column:median_value})\n",
        "\n",
        "    elif d_type=='string':\n",
        "      df=df.fillna({column:'Unknown'})\n",
        "\n",
        "    else:\n",
        "      df=df.fillna({column:'unknown'})\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "filled_df=fill_missing_values(df)\n",
        "\n",
        "filled_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNS_FFHH7xhS",
        "outputId": "28fa5455-1820-4c28-fadb-cd993e018f12"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Customer_ID: long (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Last_Visit: string (nullable = true)\n",
            " |-- Purchase_Amount: long (nullable = true)\n",
            "\n",
            "[('Customer_ID', 'bigint'), ('Age', 'bigint'), ('Region', 'string'), ('Gender', 'string'), ('Last_Visit', 'string'), ('Purchase_Amount', 'bigint')]\n",
            "+-----------+----+------+------+----------+---------------+\n",
            "|Customer_ID| Age|Region|Gender|Last_Visit|Purchase_Amount|\n",
            "+-----------+----+------+------+----------+---------------+\n",
            "|          1|  25| North|     M|2025-01-01|            150|\n",
            "|          2|NULL|  East|  NULL|2025-01-02|           NULL|\n",
            "|          3|  30| South|     F|      NULL|            200|\n",
            "|          4|  22|  NULL|     M|2025-01-03|            180|\n",
            "|          5|  28|  West|     F|      NULL|           NULL|\n",
            "+-----------+----+------+------+----------+---------------+\n",
            "\n",
            "+-----------+---+-------+-------+----------+---------------+\n",
            "|Customer_ID|Age| Region| Gender|Last_Visit|Purchase_Amount|\n",
            "+-----------+---+-------+-------+----------+---------------+\n",
            "|          1| 25|  North|      M|2025-01-01|            150|\n",
            "|          2| 25|   East|Unknown|2025-01-02|            180|\n",
            "|          3| 30|  South|      F|   Unknown|            200|\n",
            "|          4| 22|Unknown|      M|2025-01-03|            180|\n",
            "|          5| 28|   West|      F|   Unknown|            180|\n",
            "+-----------+---+-------+-------+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}