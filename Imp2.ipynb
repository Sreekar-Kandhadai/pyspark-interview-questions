{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8VB7b4PCAY/Fzd03betzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar-Kandhadai/pyspark-interview-questions/blob/main/Imp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJuH_siLbz3V"
      },
      "outputs": [],
      "source": [
        "𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧:\n",
        "You are working as a Data Engineer for a retail company that operates in multiple\n",
        "regions. The sales data is collected daily, and the company wants to analyze the\n",
        "performance of each product across different regions. The data is stored in a\n",
        "PySpark DataFrame with the following schema:The management has requested a report\n",
        "where each region becomes a column and the values represent the total sales for\n",
        "each product in that region. Your task is to write PySpark code to generate this pivot table.\n",
        "\n",
        "Task:\n",
        "1. Load the sample data into a PySpark DataFrame.\n",
        "2. Use PySpark's pivot functionality to create a table where:\n",
        "Each region is a column.\n",
        "The rows represent the products.\n",
        "The values are the total sales for each product in each region.\n",
        "3. Provide the output DataFrame in a user-friendly format for the stakeholders.\n",
        "\n",
        "𝐬𝐜𝐡𝐞𝐦𝐚 𝐚𝐧𝐝 𝐝𝐚𝐭𝐚𝐬𝐞𝐭\n",
        "\n",
        "Sample Data data = [ (\"A\", \"North\", 100), (\"B\", \"East\", 200), (\"A\", \"East\", 150)\n",
        ", (\"C\", \"North\", 300), (\"B\", \"South\", 400), (\"C\", \"East\", 250) ]\n",
        "\n",
        "\n",
        "columns = [\"Product\", \"Region\", \"Sales\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark=SparkSession.builder.appName(\"learning\").getOrCreate()\n",
        "\n",
        "data=[ (\"A\", \"North\", 100), (\"B\", \"East\", 200), (\"A\", \"East\", 150)\n",
        ", (\"C\", \"North\", 300), (\"B\", \"South\", 400), (\"C\", \"East\", 250) ]\n",
        "\n",
        "schema=[\"Product\", \"Region\", \"Sales\"]\n",
        "\n",
        "df=spark.createDataFrame(data,schema)\n",
        "\n",
        "df.show()\n",
        "\n",
        "df1=df.groupBy('product').pivot('Region').sum('Sales')\n",
        "\n",
        "df1.show()\n",
        "\n",
        "df2=df.groupBy('product').pivot('Region').agg(sum('Sales'))\n",
        "\n",
        "df2.show()\n",
        "\n",
        "# Note aggregate is used to perform multiple aggregations on  different columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0SpnrQQemMF",
        "outputId": "090b8a7f-7b33-47d7-b6a9-6da5801f744b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----+\n",
            "|Product|Region|Sales|\n",
            "+-------+------+-----+\n",
            "|      A| North|  100|\n",
            "|      B|  East|  200|\n",
            "|      A|  East|  150|\n",
            "|      C| North|  300|\n",
            "|      B| South|  400|\n",
            "|      C|  East|  250|\n",
            "+-------+------+-----+\n",
            "\n",
            "+-------+----+-----+-----+\n",
            "|product|East|North|South|\n",
            "+-------+----+-----+-----+\n",
            "|      B| 200| NULL|  400|\n",
            "|      C| 250|  300| NULL|\n",
            "|      A| 150|  100| NULL|\n",
            "+-------+----+-----+-----+\n",
            "\n",
            "+-------+----+-----+-----+\n",
            "|product|East|North|South|\n",
            "+-------+----+-----+-----+\n",
            "|      B| 200| NULL|  400|\n",
            "|      C| 250|  300| NULL|\n",
            "|      A| 150|  100| NULL|\n",
            "+-------+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}