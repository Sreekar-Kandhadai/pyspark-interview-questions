{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAgCVgPBs5u5FGyxO2Uhuu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar-Kandhadai/pyspark-interview-questions/blob/main/zensar_rolling_average.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leNo8-rZsyaY"
      },
      "outputs": [],
      "source": [
        "ùêêùêÆùêûùê¨ùê≠ùê¢ùê®ùêß\n",
        "You are given a dataset of stock prices with the following columns:\n",
        "\n",
        "- stock_id: Unique identifier for the stock.\n",
        "- date: The date of the stock price.\n",
        "- price: The price of the stock on the given date.\n",
        "\n",
        "Your task is to calculate the 3-day rolling average of the stock price (rolling_avg) for each stock (stock_id) using a sliding window, ensuring the results are partitioned by stock_id and ordered by date.\n",
        "\n",
        "ùê¨ùêúùê°ùêûùê¶ùêö\n",
        "data = [ (\"A\", \"2023-01-01\", 100), (\"A\", \"2023-01-02\", 105),\n",
        "(\"A\", \"2023-01-03\", 110), (\"A\", \"2023-01-04\", 120),\n",
        "(\"B\", \"2023-01-01\", 50), (\"B\", \"2023-01-02\", 55),\n",
        "(\"B\", \"2023-01-03\", 60), (\"B\", \"2023-01-04\", 65), ]\n",
        "\n",
        "# Define schema columns = [\"stock_id\", \"date\", \"price\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark=SparkSession.builder.appName(\"learning\").getOrCreate()\n",
        "\n",
        "data= [ (\"A\", \"2023-01-01\", 100), (\"A\", \"2023-01-02\", 105),\n",
        "(\"A\", \"2023-01-03\", 110), (\"A\", \"2023-01-04\", 120),\n",
        "(\"B\", \"2023-01-01\", 50), (\"B\", \"2023-01-02\", 55),\n",
        "(\"B\", \"2023-01-03\", 60), (\"B\", \"2023-01-04\", 65), ]\n",
        "\n",
        "schema=[\"stock_id\", \"date\", \"price\"]\n",
        "\n",
        "df=spark.createDataFrame(data,schema)\n",
        "\n",
        "df.show()\n",
        "\n",
        "window_spec=Window.partitionBy('stock_id').orderBy('date').rowsBetween(-2,0)\n",
        "\n",
        "df1=df.withColumn('rolling_avg',avg('price').over(window_spec))\n",
        "\n",
        "df1.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4isdZ66tapR",
        "outputId": "6d99f5c2-0649-4ee0-c10a-f57bed89924a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+-----+\n",
            "|stock_id|      date|price|\n",
            "+--------+----------+-----+\n",
            "|       A|2023-01-01|  100|\n",
            "|       A|2023-01-02|  105|\n",
            "|       A|2023-01-03|  110|\n",
            "|       A|2023-01-04|  120|\n",
            "|       B|2023-01-01|   50|\n",
            "|       B|2023-01-02|   55|\n",
            "|       B|2023-01-03|   60|\n",
            "|       B|2023-01-04|   65|\n",
            "+--------+----------+-----+\n",
            "\n",
            "+--------+----------+-----+------------------+\n",
            "|stock_id|      date|price|       rolling_avg|\n",
            "+--------+----------+-----+------------------+\n",
            "|       A|2023-01-01|  100|             100.0|\n",
            "|       A|2023-01-02|  105|             102.5|\n",
            "|       A|2023-01-03|  110|             105.0|\n",
            "|       A|2023-01-04|  120|111.66666666666667|\n",
            "|       B|2023-01-01|   50|              50.0|\n",
            "|       B|2023-01-02|   55|              52.5|\n",
            "|       B|2023-01-03|   60|              55.0|\n",
            "|       B|2023-01-04|   65|              60.0|\n",
            "+--------+----------+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}